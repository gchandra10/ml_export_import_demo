# Export Import Models across Unity Catalog Metastores

# Name of the workflow
name: Model Export Import UI Variables

# Trigger the workflow manually through the GitHub UI
on: 
  workflow_dispatch: # Manual trigger, you can customize it further if needed

jobs:
  export-import-model:
    runs-on: ubuntu-latest # Specify the environment to run this job, using the latest Ubuntu version

    env:
      # Environment variables sourced from GitHub Secrets for secure access
      DATABRICKS_SOURCE_HOST: ${{ secrets.DATABRICKS_SOURCE_HOST }}
      DATABRICKS_SOURCE_TOKEN: ${{ secrets.DATABRICKS_SOURCE_TOKEN }}
      DATABRICKS_DESTINATION_HOST: ${{ secrets.DATABRICKS_DESTINATION_HOST }}
      DATABRICKS_DESTINATION_TOKEN: ${{ secrets.DATABRICKS_DESTINATION_TOKEN }}

      # Custom environment variables for model and experiment details
      MODEL_NAME: ${{ vars.modelName }} # The name of the model to export (source_catalog.schema.model)
      DES_MODELNAME: ${{ vars.desModelName }} # The name of the destination model (des_catalog.schema.model)
      EXPERIMENT_NAME: ${{ vars.experimentName }} # The name of the experiment associated with the model
      TMP_FOLDER_NAME: "/tmp/${{ vars.modelName }}" # Temporary folder for storing the exported model
      EXPERIMENT_PATH: "/Shared/${{ vars.experimentName }}" # Path to the experiment in Databricks
      STAGES: ${{ vars.stages }} # Stages to export (None means all stages)
      EXPORT_LATEST_VERSION_ONLY: ${{ vars.exportLatestVersionOnly }} # Whether to export only the latest version of the model
      NOTEBOOK_FORMAT: ${{ vars.notebookFormat }} # Format for exporting the notebooks

    steps:
      # Step 1: Check out the code from the repository
      - name: Check out code
        uses: actions/checkout@v4

      # Step 2: Set up Python with the specified version (3.11)
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # Step 3: Install the mlflow-export-import library from GitHub
      - name: Install mlflow-export-import library
        run:
          pip install git+https://github.com/mlflow/mlflow-export-import/#egg=mlflow-export-import

      # Step 4: Display the name of the temporary folder for debugging
      - name: Displaying temporary folder name
        run: |
          echo "Temporary folder: ${{ env.TMP_FOLDER_NAME }}"

      # Step 5: Create the temporary folder if it doesn't already exist
      - name: Creating a Temp folder
        run: |
          mkdir -p ${{ env.TMP_FOLDER_NAME }}

      # Step 6: Export the model from the source Databricks workspace
      - name: Exporting given model
        run: |
          export MLFLOW_TRACKING_URI=databricks-uc
          export DATABRICKS_HOST=${{ env.DATABRICKS_SOURCE_HOST }}
          export DATABRICKS_TOKEN=${{ env.DATABRICKS_SOURCE_TOKEN }}
          export-model --output-dir ${{ env.TMP_FOLDER_NAME }} --model ${{ env.MODEL_NAME }} --notebook-formats ${{ env.NOTEBOOK_FORMAT }} --export-latest-versions ${{ env.EXPORT_LATEST_VERSION_ONLY }} --stages ${{ env.STAGES }}

      # Step 7: List the contents of the temporary folder to verify the export
      - name: Listing temp model folder
        run: ls -lah ${{ env.TMP_FOLDER_NAME }}

      # Step 8: Import the model into the destination Databricks workspace
      - name: Importing the model
        run: |
          export MLFLOW_TRACKING_URI=databricks-uc
          export DATABRICKS_HOST=${{ env.DATABRICKS_DESTINATION_HOST }}
          export DATABRICKS_TOKEN=${{ env.DATABRICKS_DESTINATION_TOKEN }}
          import-model --input-dir ${{ env.TMP_FOLDER_NAME }} --model ${{ env.DES_MODELNAME }} --experiment-name ${{ env.EXPERIMENT_PATH }} --delete-model True --verbose True
